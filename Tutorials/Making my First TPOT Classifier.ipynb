{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9710734613070506\n",
      "Generation 2 - Current best internal CV score: 0.9710734613070506\n",
      "Generation 3 - Current best internal CV score: 0.9710734613070506\n",
      "Generation 4 - Current best internal CV score: 0.973285274533643\n",
      "Generation 5 - Current best internal CV score: 0.9740399915147752\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=gini, max_features=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=100)\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we load the digits we imported from sklearn.datasets into a variable we call digitsweloaded\n",
    "# When we load it, notice it actually loads into two arrays: one with our \"data\" and one with our \"target\"\n",
    "        # aka it's like: \n",
    "        # observations, target = datasets.load_diabetes(return_X_y = True)\n",
    "digitsweloaded = load_digits()\n",
    "X_fortraining, X_testedon, y_fortraining, y_testedon = train_test_split(digitsweloaded.data, digitsweloaded.target,\n",
    "                                                                    train_size=0.75, test_size=0.25)\n",
    "# by importing a train_test_split it's very convienient and splits up the data into test/training for us instead of us doing it manually like you first did\n",
    "\n",
    "# Here we're initializing our algorithm object (aka tpot) and giving it certain parameters\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_fortraining, y_fortraining)\n",
    "print(tpot.score(X_testedon, y_testedon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.export('tpot.first.pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
